{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e14b71d",
   "metadata": {},
   "source": [
    "------\n",
    "## Importing required libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e93f76f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98686a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "#%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7539cd7",
   "metadata": {},
   "source": [
    "-------\n",
    "## Audio Utilities: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ead854c6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class AudioUtil ():\n",
    "    \n",
    "    @staticmethod\n",
    "    def open (audio_file):\n",
    "        sig, sr = torchaudio.load(audio_file)\n",
    "        return (sig, sr) \n",
    "    \n",
    "    @staticmethod\n",
    "    def spectro_gram (aud, n_mels = 16, n_fft = 1024, hop_len = 1024/2):\n",
    "        sig, sr = aud\n",
    "        top_db = 80\n",
    "        spec = transforms.MelSpectrogram(sr,n_fft = n_fft, hop_length = hop_len, n_mels = n_mels)(sig)\n",
    "        spec = transforms.AmplitudeToDB(top_db = top_db)(spec)\n",
    "        return (spec)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3956282d",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Sound data set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d4bf08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundDS (Dataset): \n",
    "    \n",
    "    def __init__ (self, df, data_path):\n",
    "        self.df = df\n",
    "        self.data_path = str (data_path)\n",
    "        self.sr = 48000\n",
    "        \n",
    "    def __len__ (self):        \n",
    "        return (len(self.df))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        audio_file = self.data_path + self.df.loc[idx, \"realtive_path\"]\n",
    "        class_id = torch.tensor(self.df.loc[idx, 'Y'])\n",
    "        aud = AudioUtil.open(audio_file)\n",
    "        sgram = AudioUtil.spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=1024)\n",
    "        sgram_m, sgram_s = sgram.mean(), sgram.std()\n",
    "        sgram = (sgram -  sgram_m)/sgram_s\n",
    "\n",
    "        return sgram, class_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699fb551",
   "metadata": {},
   "source": [
    "------\n",
    "## Building a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df2562f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(64*141, 64) # Fully connected layer with 100 hidden neurons\n",
    "        self.fc2 = torch.nn.Linear(64, 64) # Fully connected layer with num_classes outputs\n",
    "        self.fc3 = torch.nn.Linear(64, 64) # Fully connected layer with num_classes outputs\n",
    "        self.fc4 = torch.nn.Linear(64, 64) # Fully connected layer with num_classes outputs\n",
    "        self.fc5 = torch.nn.Linear(64, num_classes) # Fully connected layer with num_classes outputs\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,64*141) # reshape the input tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return F.log_softmax(x,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0080214a",
   "metadata": {},
   "source": [
    "------\n",
    "## Working on the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02e7556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>realtive_path</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/experiments/exp0/audio_records/dis0/output0_0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/experiments/exp0/audio_records/dis0/output0_1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/experiments/exp0/audio_records/dis0/output0_2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/experiments/exp0/audio_records/dis0/output0_3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/experiments/exp0/audio_records/dis0/output0_4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       realtive_path  Y\n",
       "0  /experiments/exp0/audio_records/dis0/output0_0...  0\n",
       "1  /experiments/exp0/audio_records/dis0/output0_1...  0\n",
       "2  /experiments/exp0/audio_records/dis0/output0_2...  0\n",
       "3  /experiments/exp0/audio_records/dis0/output0_3...  0\n",
       "4  /experiments/exp0/audio_records/dis0/output0_4...  0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/mohammeda.salha/Desktop/MISCADA/The final project/The code/Dataframes/LL_exp1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9951d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=r'/Users/mohammeda.salha/Desktop/MISCADA/The final project/The code'\n",
    "myds = SoundDS(df, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "356abef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
    "# Create training and validation data loaders\n",
    "train_dl =torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=64, shuffle=True)\n",
    "print(num_train)\n",
    "print(num_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97c283a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model and put it on the GPU if available\n",
    "model = NeuralNetwork()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "# Check that it is on Cuda\n",
    "next(model.parameters()).device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3609c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 1.3723, train acc: 0.4500, val loss: 0.8914, val acc: 0.8467\n",
      "Epoch 2/20, train loss: 0.5592, train acc: 0.8983, val loss: 0.2478, val acc: 0.8400\n",
      "Epoch 3/20, train loss: 0.2085, train acc: 0.8983, val loss: 0.0953, val acc: 1.0000\n",
      "Epoch 4/20, train loss: 0.0724, train acc: 1.0000, val loss: 0.0262, val acc: 1.0000\n",
      "Epoch 5/20, train loss: 0.0177, train acc: 1.0000, val loss: 0.0056, val acc: 1.0000\n",
      "Epoch 6/20, train loss: 0.0038, train acc: 1.0000, val loss: 0.0022, val acc: 1.0000\n",
      "Epoch 7/20, train loss: 0.0012, train acc: 1.0000, val loss: 0.0008, val acc: 1.0000\n",
      "Epoch 8/20, train loss: 0.0006, train acc: 1.0000, val loss: 0.0007, val acc: 1.0000\n",
      "Epoch 9/20, train loss: 0.0004, train acc: 1.0000, val loss: 0.0005, val acc: 1.0000\n",
      "Epoch 10/20, train loss: 0.0003, train acc: 1.0000, val loss: 0.0004, val acc: 1.0000\n",
      "Epoch 11/20, train loss: 0.0003, train acc: 1.0000, val loss: 0.0005, val acc: 1.0000\n",
      "Epoch 12/20, train loss: 0.0003, train acc: 1.0000, val loss: 0.0003, val acc: 1.0000\n",
      "Epoch 13/20, train loss: 0.0002, train acc: 1.0000, val loss: 0.0003, val acc: 1.0000\n",
      "Epoch 14/20, train loss: 0.0002, train acc: 1.0000, val loss: 0.0002, val acc: 1.0000\n",
      "Epoch 15/20, train loss: 0.0002, train acc: 1.0000, val loss: 0.0002, val acc: 1.0000\n",
      "Epoch 16/20, train loss: 0.0002, train acc: 1.0000, val loss: 0.0002, val acc: 1.0000\n",
      "Epoch 17/20, train loss: 0.0002, train acc: 1.0000, val loss: 0.0002, val acc: 1.0000\n",
      "Epoch 18/20, train loss: 0.0001, train acc: 1.0000, val loss: 0.0002, val acc: 1.0000\n",
      "Epoch 19/20, train loss: 0.0001, train acc: 1.0000, val loss: 0.0002, val acc: 1.0000\n",
      "Epoch 20/20, train loss: 0.0001, train acc: 1.0000, val loss: 0.0002, val acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "num_epochs = 20\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "val_loss_history = []\n",
    "val_acc_history = []\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Loop through the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "\n",
    "    # set model to train mode\n",
    "    model.train()\n",
    "    # iterate over the training data\n",
    "    for data in train_dl:\n",
    "        inputs, labels = data[0], data[1] \n",
    "        # Normalize the inputs\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        #compute the loss\n",
    "        loss = F.nll_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # increment the running loss and accuracy\n",
    "        #print(loss.item())\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "        #print((outputs.argmax(1) == labels).sum())\n",
    "    # calculate the average training loss and accuracy\n",
    "    train_loss /= len(train_dl)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc /= len(train_dl.dataset)\n",
    "    train_acc_history.append(train_acc)\n",
    "\n",
    "    # set the model to evaluation mode\n",
    "    #model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dl:\n",
    "            outputs = model(inputs)\n",
    "            loss = F.nll_loss(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    # calculate the average validation loss and accuracy\n",
    "    val_loss /= len(val_dl)\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_acc /= len(val_dl.dataset)\n",
    "    val_acc_history.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, train loss: {train_loss:.4f}, train acc: {train_acc:.4f}, val loss: {val_loss:.4f}, val acc: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197e2b31",
   "metadata": {},
   "source": [
    "-------\n",
    "## CNN model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb4981f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    " \n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self,num_classes=5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(5,5), stride=1, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    " \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(5,5), stride=1, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    " \n",
    "        self.flat = nn.Flatten()\n",
    " \n",
    "        self.fc3 = nn.Linear(65280, 512)\n",
    "        self.act3 = nn.ReLU()\n",
    " \n",
    "        self.fc4 = nn.Linear(512, num_classes)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.conv1(x))\n",
    "        x = self.act2(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.act3(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e8c19ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: model accuracy 56.00%\n",
      "Epoch 1: model accuracy 96.67%\n",
      "Epoch 2: model accuracy 96.00%\n",
      "Epoch 3: model accuracy 100.00%\n",
      "Epoch 4: model accuracy 98.00%\n",
      "Epoch 5: model accuracy 100.00%\n",
      "Epoch 6: model accuracy 100.00%\n",
      "Epoch 7: model accuracy 100.00%\n",
      "Epoch 8: model accuracy 100.00%\n",
      "Epoch 9: model accuracy 100.00%\n",
      "Epoch 10: model accuracy 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5h/yplt5td549x2mqvcd96blk9m0000gn/T/ipykernel_80398/2455650786.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# forward, backward, and then weight update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5h/yplt5td549x2mqvcd96blk9m0000gn/T/ipykernel_80398/854558961.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CNNModel()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    " \n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    for inputs, labels in train_dl:\n",
    "\n",
    "        # forward, backward, and then weight update\n",
    "        y_pred = model(inputs)\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "    acc = 0\n",
    "    count = 0\n",
    "    for inputs, labels in val_dl:\n",
    "        y_pred = model(inputs)\n",
    "        acc += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
    "        count += len(labels)\n",
    "    acc /= count\n",
    "    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))\n",
    " \n",
    "#torch.save(model.state_dict(), \"cifar10model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429cff47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
